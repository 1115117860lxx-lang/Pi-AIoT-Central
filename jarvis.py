"""
é¡¹ç›®åç§°: Raspberry Pi 5 AIoT ç¦»çº¿è¯­éŸ³ç®¡å®¶ (Jarvis)
ç¡¬ä»¶å¹³å°: Raspberry Pi 5 (8GB)
æ ¸å¿ƒæŠ€æœ¯æ ˆ:
  - å¬è§‰ (STT): Vosk (ç¦»çº¿æ¨¡åž‹: vosk-model-small-cn-0.22)
  - å¤§è„‘ (LLM): Ollama + Qwen2.5:1.5b (æœ¬åœ°è¿è¡Œ)
  - è§†è§‰ (TTS): pyttsx3 + espeak (ç¦»çº¿è¯­éŸ³åˆæˆ)
  - æŽ§åˆ¶ (GPIO): RPi.GPIO
ä½œè€…: æ–°
æ—¥æœŸ: 2025
"""

import os
import json
import pyaudio
import requests
import pyttsx3
import RPi.GPIO as GPIO
import time
from vosk import Model, KaldiRecognizer

# --- 1. ç¡¬ä»¶é…ç½®ä¸Žåˆå§‹åŒ– ---
PIN_LIGHT = 17  # ç¯å…‰ GPIO
PIN_FAN = 27    # é£Žæ‰‡ GPIO

# å¼ºåˆ¶æ¸…ç† GPIO çŠ¶æ€ï¼Œé˜²æ­¢è¢«æ—§è¿›ç¨‹å ç”¨
try:
    GPIO.setmode(GPIO.BCM)
    GPIO.cleanup()
except:
    pass

try:
    GPIO.setmode(GPIO.BCM)
    GPIO.setup(PIN_LIGHT, GPIO.OUT, initial=GPIO.LOW)
    GPIO.setup(PIN_FAN, GPIO.OUT, initial=GPIO.LOW)
    IS_PI = True
    print(f"âœ… ç¡¬ä»¶å°±ç»ªï¼æŽ§åˆ¶å¼•è„š: ç¯={PIN_LIGHT}, é£Žæ‰‡={PIN_FAN}")
    
    # --- ðŸ’¡ å¼€æœºè‡ªæ£€ (è§†è§‰åé¦ˆ) ---
    print("ðŸ‘€ ç¡¬ä»¶è‡ªæ£€ä¸­ (ç¯å…‰é—ªçƒ)...")
    for _ in range(2):
        GPIO.output(PIN_LIGHT, GPIO.HIGH)
        time.sleep(0.3)
        GPIO.output(PIN_LIGHT, GPIO.LOW)
        time.sleep(0.3)
    print("âœ… è‡ªæ£€å®Œæˆã€‚")

except Exception as e:
    IS_PI = False
    print(f"âš ï¸ è¿›å…¥æ¨¡æ‹Ÿæ¨¡å¼ (GPIO é”™è¯¯): {e}")

# --- 2. ç¦»çº¿è¯­éŸ³åˆæˆ (TTS) ---
engine = pyttsx3.init()

# è‡ªåŠ¨å¯»æ‰¾å¹¶åˆ‡æ¢ä¸­æ–‡è¯­éŸ³åŒ…
voices = engine.getProperty('voices')
found_zh = False
for v in voices:
    if 'zh' in v.id or 'chinese' in v.name.lower():
        engine.setProperty('voice', v.id)
        found_zh = True
        print(f"âœ… TTS å·²åˆ‡æ¢ä¸­æ–‡: {v.id}")
        break

if not found_zh:
    try:
        engine.setProperty('voice', 'zh') # å¼ºåˆ¶å°è¯•
    except:
        pass

engine.setProperty('rate', 165)  # è¯­é€Ÿ
engine.setProperty('volume', 1.0) # éŸ³é‡

def speak(text):
    """ æ–‡å­—è½¬è¯­éŸ³è¾“å‡º """
    print(f"ðŸ¤– Jarvis: {text}")
    try:
        engine.say(text)
        engine.runAndWait()
    except:
        pass

# --- 3. ç¦»çº¿è¯­éŸ³è¯†åˆ« (Vosk) ---
if not os.path.exists("model"):
    print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° 'model' æ–‡ä»¶å¤¹ï¼Œè¯·ä¸‹è½½ Vosk ä¸­æ–‡æ¨¡åž‹ã€‚")
    exit(1)

# å±è”½åº•å±‚ ALSA éŸ³é¢‘é©±åŠ¨çš„å†—ä½™æŠ¥é”™
try:
    from ctypes import *
    ERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)
    def py_error_handler(filename, line, function, err, fmt): pass
    c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)
    asound = cdll.LoadLibrary('libasound.so')
    asound.snd_lib_error_set_handler(c_error_handler)
except:
    pass

print("â³ æ­£åœ¨åŠ è½½ Vosk ç¦»çº¿æ¨¡åž‹...")
model = Model("model")
rec = KaldiRecognizer(model, 16000)
p = pyaudio.PyAudio()

# æ‰“å¼€éº¦å…‹é£Žæµ (é‡‡æ ·çŽ‡ 16000)
stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=4000)
stream.start_stream()

# --- 4. AI å¤§è„‘å¤„ç† (Ollama + è§„åˆ™å…œåº•) ---
def ask_ai(text):
    url = "http://127.0.0.1:11434/api/chat"
    
    # System Prompt: å®šä¹‰ AI çš„äººè®¾å’Œè¾“å‡ºæ ¼å¼
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç®¡å®¶ã€‚
    ä»»åŠ¡ï¼šåˆ¤æ–­ç”¨æˆ·æ„å›¾ï¼Œè¿”å›ž JSONã€‚
    è§„åˆ™ï¼š
    1. å¦‚æžœç”¨æˆ·æƒ³æŽ§åˆ¶è®¾å¤‡ï¼Œå¿…é¡»è®¾ç½® "device" (light/fan) å’Œ "action" (on/off)ã€‚
    2. å¦‚æžœåªæ˜¯é—²èŠï¼Œ"device" è®¾ä¸º nullã€‚
    
    ç¤ºä¾‹ï¼š
    ç”¨æˆ·ï¼šæŠŠç¯æ‰“å¼€ -> {"device": "light", "action": "on", "reply": "å¥½çš„ï¼Œç¯äº®äº†"}
    ç”¨æˆ·ï¼šä½ å¥½ -> {"device": null, "action": null, "reply": "ä½ å¥½å‘€ï¼"}
    """
    
    ai_data = {"device": None, "action": None, "reply": "æˆ‘æ²¡å¬æ¸…"}
    
    # 1. å°è¯•è¯·æ±‚æœ¬åœ° LLM
    try:
        res = requests.post(url, json={
            "model": "qwen2.5:1.5b",
            "messages": [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': text}
            ],
            "stream": False
        }, timeout=10)
        
        raw = res.json()['message']['content']
        # æ¸…æ´—æ•°æ®ï¼Œæå– JSON
        clean = raw.replace("```json", "").replace("```", "").strip()
        import re
        match = re.search(r'\{.*\}', clean, re.DOTALL)
        if match:
            ai_data = json.loads(match.group())
        else:
            ai_data = {"reply": clean, "device": None, "action": None}
            
    except:
        return {"reply": "Ollama æœåŠ¡æœªå¯åŠ¨", "device": None}

    # ðŸ”¥ 2. è§„åˆ™å…œåº• (Rule-based Fallback) ðŸ”¥
    # å¦‚æžœå°æ¨¡åž‹â€œæ¼æŠ“â€äº†æŒ‡ä»¤ï¼Œä½¿ç”¨å…³é”®è¯å¼ºåˆ¶ä¿®æ­£ï¼Œç¡®ä¿æŽ§åˆ¶æˆåŠŸçŽ‡ 100%
    if ai_data.get("device") is None:
        text_lower = text.lower()
        # print("âš ï¸ æ£€æµ‹åˆ° AI æœªè¯†åˆ«è®¾å¤‡ï¼Œå¯åŠ¨è§„åˆ™å…œåº•æ£€æŸ¥...")
        
        if "ç¯" in text_lower:
            if any(x in text_lower for x in ["å¼€", "äº®", "open", "on"]):
                ai_data.update({"device": "light", "action": "on", "reply": "å¥½çš„ï¼Œç¯å·²å¼€å¯ (å…œåº•)"})
            elif any(x in text_lower for x in ["å…³", "ç­", "close", "off"]):
                ai_data.update({"device": "light", "action": "off", "reply": "å¥½çš„ï¼Œç¯å·²å…³é—­ (å…œåº•)"})
                
        elif "é£Žæ‰‡" in text_lower:
            if any(x in text_lower for x in ["å¼€", "è½¬", "open", "on"]):
                ai_data.update({"device": "fan", "action": "on", "reply": "é£Žæ‰‡å¯åŠ¨ (å…œåº•)"})
            elif any(x in text_lower for x in ["å…³", "åœ", "close", "off"]):
                ai_data.update({"device": "fan", "action": "off", "reply": "é£Žæ‰‡åœæ­¢ (å…œåº•)"})

    return ai_data

# --- 5. ä¸»å¾ªçŽ¯ ---
print("\nâœ… ç³»ç»Ÿå°±ç»ªï¼è¯·è¯´è¯...")
speak("ç³»ç»Ÿå¯åŠ¨å®Œæ¯•")

try:
    while True:
        data = stream.read(4000, exception_on_overflow=False)
        if len(data) == 0: break

        # Vosk å®žæ—¶ç›‘å¬
        if rec.AcceptWaveform(data):
            result = json.loads(rec.Result())
            text = result['text'].replace(" ", "")
            
            if text:
                print(f"ðŸ‘‚ å¬åˆ°: {text}")
                # å…³é”®è¯å”¤é†’è¿‡æ»¤ï¼Œé˜²æ­¢æ‚éŸ³è¯¯è§¦
                keywords = ["ç¯", "é£Žæ‰‡", "æ‰“å¼€", "å…³", "ä½ å¥½", "æ˜¯è°", "ç¬‘è¯", "å¤©æ°”", "è´¾ç»´æ–¯"]
                
                if any(k in text for k in keywords):
                    action_data = ask_ai(text)
                    print(f"ðŸ§  AI æœ€ç»ˆå†³ç­–: {action_data}") 
                    
                    device = action_data.get('device')
                    action = action_data.get('action')
                    reply = action_data.get('reply', 'å¥½çš„')
                    
                    # ç¡¬ä»¶æ‰§è¡Œé€»è¾‘ (å…¼å®¹å¤§å°å†™)
                    if device and device.lower() == 'light' and IS_PI:
                        state = GPIO.HIGH if action == 'on' else GPIO.LOW
                        GPIO.output(PIN_LIGHT, state)
                        print(f"ðŸ’¡ [ç¡¬ä»¶æ“ä½œ] ç¯ -> {action}")
                        
                    elif device and device.lower() == 'fan' and IS_PI:
                        state = GPIO.HIGH if action == 'on' else GPIO.LOW
                        GPIO.output(PIN_FAN, state)
                        print(f"ðŸ’¨ [ç¡¬ä»¶æ“ä½œ] é£Žæ‰‡ -> {action}")
                    
                    speak(reply)

except KeyboardInterrupt:
    print("\né€€å‡ºç³»ç»Ÿ")
    stream.stop_stream()
    stream.close()
    p.terminate()
    if IS_PI: GPIO.cleanup()